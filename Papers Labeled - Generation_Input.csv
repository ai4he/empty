ID,Title,Authors,Year,Abstract,URL,Citations,DOI,Venue
1looprenormalisabili-2025,1-loop renormalisability of integrable sigma-models from 4d Chern-Simons theory,Sylvain Lacroix; Nat Levine; A. Wallberg,2025,"Large families of integrable 2d œÉ-models have been constructed at the classical level, partly motivated by the utility of integrability on the string worldsheet. It is natural to ask whether these theories are renormalisable at the quantum level, and whether they define quantum integrable field theories. By considering examples, a folk theorem has emerged: the classically integrable œÉ-models always turn out to be renormalisable, at least at 1-loop order. We prove this theorem for a large class of models engineered on surface defects in the 4d Chern-Simons theory by Costello and Yamazaki. We derive the flow of the ‚Äòtwist 1-form‚Äô (a 4d coupling constant that distinguishes different 2d models), proving earlier conjectures and extending previous results. Our approach is general, using the ‚Äòuniversal‚Äô form of 2d integrable models‚Äô UV divergences in terms of their Lax connection and reinterpreting the result in the language of 4d Chern-Simons. These results apply equally to rational, trigonometric and elliptic models.",https://www.semanticscholar.org/paper/166481935d23e1b994979e917c839e394f7dfa3c,2,10.1007/JHEP09(2025)153,Journal of High Energy Physics
acombinatorialidenti-2025,A Combinatorial Identities Benchmark for Theorem Proving via Automated Theorem Generation,Beibei Xiong; Hangyu Lv; Haojia Shan; Jianlin Wang; Zhengfeng Yang; Lihong Zhi,2025,"Large language models (LLMs) have significantly advanced formal theorem proving, yet the scarcity of high-quality training data constrains their capabilities in complex mathematical domains. Combinatorics, a cornerstone of mathematics, provides essential tools for analyzing discrete structures and solving optimization problems. However, its inherent complexity makes it particularly challenging for automated theorem proving (ATP) for combinatorial identities. To address this, we manually construct LeanComb, combinatorial identities benchmark in Lean, which is, to our knowledge, the first formalized theorem proving benchmark built for combinatorial identities. We develop an Automated Theorem Generator for Combinatorial Identities, ATG4CI, which combines candidate tactics suggested by a self-improving large language model with a Reinforcement Learning Tree Search approach for tactic prediction. By utilizing ATG4CI, we generate a LeanComb-Enhanced dataset comprising 260K combinatorial identities theorems, each with a complete formal proof in Lean, and experimental evaluations demonstrate that models trained on this dataset can generate more effective tactics, thereby improving success rates in automated theorem proving for combinatorial identities.",https://www.semanticscholar.org/paper/3caf1dde5fd351e9b979bb518034edff9569a473,3,10.48550/arXiv.2502.17840,arXiv.org
alawofemergencemaxim-2025,A Law of Emergence: Maximum Causal Power at the Mesoscale,Liang Chen,2025,"Complex systems universally exhibit emergence, where macroscopic dynamics arise from local interactions, but a predictive law governing this process has been absent. We establish and verify such a law. We define a system's causal power at a spatial scale, $\ell$, as its Effective Information (EI$_\ell$), measured by the mutual information between a targeted, maximum-entropy intervention and its outcome. From this, we derive and prove a Middle-Scale Peak Theorem: for a broad class of systems with local interactions, EI$_\ell$ is not monotonic but exhibits a strict maximum at a mesoscopic scale $\ell^*$. This peak is a necessary consequence of a fundamental trade-off between noise-averaging at small scales and locality-limited response at large scales. We provide quantitative, reproducible evidence for this law in two distinct domains: a 2D Ising model near criticality and a model of agent-based collective behavior. In both systems, the predicted unimodal peak is decisively confirmed by statistical model selection. Our work establishes a falsifiable, first-principles law that identifies the natural scale of emergence, providing a quantitative foundation for the discovery of effective theories.",https://www.semanticscholar.org/paper/57405d81f8b649849cc8bd02ff281f480616777b,,10.48550/arXiv.2508.12016,arXiv.org
absolutezeroreinforc-2025,Absolute Zero: Reinforced Self-play Reasoning with Zero Data,Andrew Zhao; Yiran Wu; Yang Yue; Tong Wu; Quentin Xu; Matthieu Lin; Shenzhi Wang; Qingyun Wu; Zilong Zheng; Gao Huang,2025,"Reinforcement learning with verifiable rewards (RLVR) has shown promise in enhancing the reasoning capabilities of large language models by learning directly from outcome-based rewards. Recent RLVR works that operate under the zero setting avoid supervision in labeling the reasoning process, but still depend on manually curated collections of questions and answers for training. The scarcity of high-quality, human-produced examples raises concerns about the long-term scalability of relying on human supervision, a challenge already evident in the domain of language model pretraining. Furthermore, in a hypothetical future where AI surpasses human intelligence, tasks provided by humans may offer limited learning potential for a superintelligent system. To address these concerns, we propose a new RLVR paradigm called Absolute Zero, in which a single model learns to propose tasks that maximize its own learning progress and improves reasoning by solving them, without relying on any external data. Under this paradigm, we introduce the Absolute Zero Reasoner (AZR), a system that self-evolves its training curriculum and reasoning ability by using a code executor to both validate proposed code reasoning tasks and verify answers, serving as an unified source of verifiable reward to guide open-ended yet grounded learning. Despite being trained entirely without external data, AZR achieves overall SOTA performance on coding and mathematical reasoning tasks, outperforming existing zero-setting models that rely on tens of thousands of in-domain human-curated examples. Furthermore, we demonstrate that AZR can be effectively applied across different model scales and is compatible with various model classes.",https://www.semanticscholar.org/paper/09b2a0f0d7c1164ab334e13e70eb0d65b5b96393,101,10.48550/arXiv.2505.03335,arXiv.org
2,Advancing mathematics by guiding human intuition with AI,"Alex Davies, Petar Veliƒçkoviƒá, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Toma≈°ev, Richard Tanburn, Peter Battaglia, Charles Blundell, Andr√°s Juh√°sz, Marc Lackenby, Geordie Williamson, Demis Hassabis, Pushmeet Kohli",2021,"The practice of mathematics involves discovering patterns and using these to formulate and prove conjectures, resulting in theorems. Since the 1960s, mathematicians have used computers to assist in the discovery of patterns and formulation of conjectures, most famously in the Birch and Swinnerton-Dyer conjecture, a Millennium Prize Problem. Here we provide examples of new fundamental results in pure mathematics that have been discovered with the assistance of machine learning—demonstrating a method by which machine learning can aid mathematicians in discovering new conjectures and theorems. We propose a process of using machine learning to discover potential patterns and relations between mathematical objects, understanding them with attribution techniques and using these observations to guide intuition and propose conjectures. We outline this machine-learning-guided framework and demonstrate its successful application to current research questions in distinct areas of pure mathematics, in each case showing how it led to meaningful mathematical contributions on important open problems: a new connection between the algebraic and geometric structure of knots, and a candidate algorithm predicted by the combinatorial invariance conjecture for symmetric groups. Our work may serve as a model for collaboration between the fields of mathematics and artificial intelligence (AI) that can achieve surprising results by leveraging the respective strengths of mathematicians and machine learning.",https://www.nature.com/articles/s41586-021-04086-x,N/A,10.1038/s41586-021-04086-x,Nature
advancingmathematics-2025,Advancing mathematics research with generative AI,Lisa Carbone,2025,"The main drawback of using generative AI models for advanced mathematics is that these models are not logical reasoning engines. However, Large Language Models, and their refinements, can pick up on patterns in higher mathematics that are difficult for humans to see. By putting the design of generative AI models to their advantage, mathematicians may use them as powerful interactive assistants that can carry out laborious tasks, generate and debug code, check examples, formulate conjectures and more. We discuss how generative AI models can be used to advance mathematics research. We also discuss their integration with Computer Algebra Systems and formal proof assistants such as Lean.",https://www.semanticscholar.org/paper/a6dd3ebdcdb865e276fce562f74996601d32bb7f,,,
agent0unleashingself-2025,Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning,Peng Xia; Peng Xia; Kaide Zeng; Jiaqi Liu; Can Qin; Fang Wu; Yiyang Zhou; Caiming Xiong; Huaxiu Yao,2025,"Large Language Model (LLM) Agents, often trained with Reinforcement Learning (RL), are constrained by a dependency on human-curated data, limiting scalability and tethering AI to human knowledge. Existing self-evolution frameworks offer an alternative but are typically restricted by the model's inherent capabilities and single-round interactions, hindering the development of complex curricula involving tool use or dynamic reasoning. We introduce Agent0, a fully autonomous framework that evolves high-performing agents without external data through multi-step co-evolution and seamless tool integration. Agent0 establishes a symbiotic competition between two agents initialized from the same base LLM: a curriculum agent that proposes increasingly challenging frontier tasks, and an executor agent that learns to solve them. We integrate external tools to enhance the executor's problem-solving capacity; this improvement, in turn, pressures the curriculum agent to construct more complex, tool-aware tasks. Through this iterative process, Agent0 establishes a self-reinforcing cycle that continuously produces high-quality curricula. Empirically, Agent0 substantially boosts reasoning capabilities, improving the Qwen3-8B-Base model by 18% on mathematical reasoning and 24% on general reasoning benchmarks. Code is available at https://github.com/aiming-lab/Agent0.",https://www.semanticscholar.org/paper/a647788b47b1bac9c137ab192316f72de52471d4,1,,
airesearcherautonomo-2025,AI-Researcher: Autonomous Scientific Innovation,Jiabin Tang; Lianghao Xia; Zhonghang Li; Chao Huang,2025,"The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.",https://www.semanticscholar.org/paper/80a0b76dedc4c3e3d365bbaececcd44a996eb38b,9,10.48550/arXiv.2505.18705,arXiv.org
10,AlphaEvolve: A coding agent for scientific and algorithmic discovery,"Alexander Novikov, Ng√¢n V≈©, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco J.R. Ruiz, Abbas Mehrabian, M. Pawan Kumar, Abigail See, Swarat Chaudhuri, George Holland, Alex Davies, Sebastian Nowozin, Pushmeet Kohli, Matej Balog",2025,"In this white paper, we present AlphaEvolve, an evolutionary coding agent that substantially enhances capabilities of state-of-the-art LLMs on highly challenging tasks such as tackling open scientific problems or optimizing critical pieces of computational infrastructure. AlphaEvolve orchestrates an autonomous pipeline of LLMs, whose task is to improve an algorithm by making direct changes to the code. Using an evolutionary approach, continuously receiving feedback from one or more evaluators, AlphaEvolve iteratively improves the algorithm, potentially leading to new scientific and practical discoveries. We demonstrate the broad applicability of this approach by applying it to a number of important computational problems. When applied to optimizing critical components of large-scale computational stacks at Google, AlphaEvolve developed a more efficient scheduling algorithm for data centers, found a functionally equivalent simplification in the circuit design of hardware accelerators, and accelerated the training of the LLM underpinning AlphaEvolve itself. Furthermore, AlphaEvolve discovered novel, provably correct algorithms that surpass state-of-the-art solutions on a spectrum of problems in mathematics and computer science, significantly expanding the scope of prior automated discovery methods (Romera-Paredes et al., 2023). Notably, AlphaEvolve developed a search algorithm that found a procedure to multiply two 4×4 complex-valued matrices using 48 scalar multiplications; offering the first improvement, after 56 years, over Strassen's algorithm in this setting. We believe AlphaEvolve and coding agents like it can have a significant impact in improving solutions of problems across many areas of science and computation.",https://arxiv.org/abs/2506.13131,N/A,10.48550/arXiv.2506.13131,arXiv
atgbenchmarkingautom-2024,ATG: Benchmarking Automated Theorem Generation for Generative Language Models,Xiaohan Lin; Qingxing Cao; Yinya Huang; Zhicheng YANG; Zhengying Liu; Zhenguo Li; Xiaodan Liang,2024,"Humans can develop new theorems to explore broader and more complex mathematical results. While current generative language models (LMs) have achieved significant improvement in automatically proving theorems, their ability to generate new or reusable theorems is still under-explored. Without the new theorems, current LMs struggle to prove harder theorems that are distant from the given hypotheses with the exponentially growing search space. Therefore, this paper proposes an Automated Theorem Generation (ATG) benchmark that evaluates whether an agent can automatically generate valuable (and possibly brand new) theorems that are applicable for downstream theorem proving as reusable knowledge. Specifically, we construct the ATG benchmark by splitting the Metamath library into three sets: axioms, library, and problem based on their proving depth. We conduct extensive experiments to investigate whether current LMs can generate theorems in the library and benefit the problem theorems proving. The results demonstrate that high-quality ATG data facilitates models' performances on downstream ATP. However, there is still room for current LMs to develop better ATG and generate more advanced and human-like theorems. We hope the new ATG challenge can shed some light on advanced complex theorem proving.",https://www.semanticscholar.org/paper/2f85aa1f80c944d2a167262e38fb9d0611e4dc7f,9,10.48550/arXiv.2405.06677,NAACL-HLT
automatedgenerationo-2024,Automated Generation of Massive Reasonable Empirical Theorems by Forward Reasoning Based on Strong Relevant Logics - A Solution to the Problem of LLM Pre-training Data Exhaustion,Jingde Cheng,2024,"Recently, it is often said that the data used for the pre-training of large language models (LLMs) have been exhausted. This paper proposes a solution to the problem: Automated generation of massive reasonable empirical theorems by forward reasoning based on strong relevant logics. In fact, this can be regarded as a part of our approach to the problems of ATF (Automated Theorem Finding) and AKA (Automated Knowledge Appreciation).",https://www.semanticscholar.org/paper/68f4e34312ed209300e3e16a67b3b5c51e2c5dd7,,10.48550/arXiv.2412.12408,arXiv.org
bioinspiredllmconver-2023,BioinspiredLLM: Conversational Large Language Model for the Mechanics of Biological and Bio‐Inspired Materials,Rachel K. Luu; M. Buehler,2023,"The study of biological materials and bio‐inspired materials science is well established; however, surprisingly little knowledge is systematically translated to engineering solutions. To accelerate discovery and guide insights, an open‐source autoregressive transformer large language model (LLM), BioinspiredLLM, is reported. The model is finetuned with a corpus of over a thousand peer‐reviewed articles in the field of structural biological and bio‐inspired materials and can be prompted to recall information, assist with research tasks, and function as an engine for creativity. The model has proven that it is able to accurately recall information about biological materials and is further strengthened with enhanced reasoning ability, as well as with Retrieval‐Augmented Generation (RAG) to incorporate new data during generation that can also help to traceback sources, update the knowledge base, and connect knowledge domains. BioinspiredLLM also has shown to develop sound hypotheses regarding biological materials design and remarkably so for materials that have never been explicitly studied before. Lastly, the model shows impressive promise in collaborating with other generative artificial intelligence models in a workflow that can reshape the traditional materials design process. This collaborative generative artificial intelligence method can stimulate and enhance bio‐inspired materials design workflows. Biological materials are at a critical intersection of multiple scientific fields and models like BioinspiredLLM help to connect knowledge domains.",https://www.semanticscholar.org/paper/8db921900955a447d389582143912eee3046fd3e,74,10.1002/advs.202306724,Advancement of science
causalstructurelearn-2023,Causal Structure Learning Supervised by Large Language Model,Taiyu Ban; Lyuzhou Chen; Derui Lyu; Xiangyu Wang; Huanhuan Chen,2023,"Causal discovery from observational data is pivotal for deciphering complex relationships. Causal Structure Learning (CSL), which focuses on deriving causal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast DAG spaces and data sparsity. The integration of Large Language Models (LLMs), recognized for their causal reasoning capabilities, offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences. However, existing approaches utilizing LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses. In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process, refining the causal DAG using feedback from LLMs. This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies. Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery. The codes are available at \url{https://github.com/tyMadara/ILS-CSL}.",https://www.semanticscholar.org/paper/9e557a199972b963d8ac064ac6e625c115c03cde,23,10.48550/arXiv.2311.11689,arXiv.org
chatrulemininglogica-2023,ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning,Linhao Luo; Jiaxin Ju; Bo Xiong; Yuan-Fang Li; Gholamreza Haffari; Shirui Pan,2023,"Logical rules are essential for uncovering the logical connections between relations, which could improve reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs to prompt LLMs to generate logical rules. To refine the generated rules, a rule ranking module estimates the rule quality by incorporating facts from existing KGs. Last, the ranked rules can be used to conduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs, w.r.t. different rule quality metrics and downstream tasks, showing the effectiveness and scalability of our method.",https://www.semanticscholar.org/paper/18664b47516ba5424ba5efa79d3f816224245325,40,10.48550/arXiv.2309.01538,Pacific-Asia Conference on Knowledge Discovery and Data Mining
coevocontinualevolut-2024,CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models,Ping Guo; Qingfu Zhang; Xi Lin,2024,"The discovery of symbolic solutions -- mathematical expressions, logical rules, and algorithmic structures -- is fundamental to advancing scientific and engineering progress. However, traditional methods often struggle with search efficiency and fail to integrate knowledge effectively. While recent large language model-based (LLM-based) approaches have demonstrated improvements in search efficiency, they lack the ability to continually refine and expand upon discovered solutions and their underlying knowledge, limiting their potential for open-ended innovation. To address these limitations, we introduce CoEvo, a novel framework that leverages large language models within an evolutionary search methodology to continually generate and refine symbolic solutions. CoEvo integrates a dynamic knowledge library, enabling open-ended innovation of solutions through effective knowledge management. Additionally, CoEvo leverages multiple representations of solutions -- including natural language, mathematical expressions, and code -- to further enhance search efficiency. By combining the reasoning capabilities of LLMs with the exploratory power of evolutionary algorithms, CoEvo significantly improves the efficiency and scope of symbolic discovery. Our experimental results demonstrate that this method not only enhances the efficiency of searching for symbolic solutions but also supports the ongoing discovery process, akin to human scientific endeavors. This study represents a first effort in conceptualizing the search for symbolic solutions as a lifelong, iterative process, marking a significant step towards harnessing LLMs in the perpetual pursuit of scientific and engineering breakthroughs. Our code is available at https://github.com/pgg3/CoEvo.",https://www.semanticscholar.org/paper/b9fcf65bbc51d4e07aa936f1eb3d66f7139517ab,3,10.48550/arXiv.2412.18890,arXiv.org
conjecturinganoverlo-2025,Conjecturing: An Overlooked Step in Formal Mathematical Reasoning,Jasivan Sivakumar; Philipp Borchert; Ronald Cardenas; Gerasimos Lampouras,2025,"Autoformalisation, the task of expressing informal mathematical statements in formal language, is often viewed as a direct translation process. This, however, disregards a critical preceding step: conjecturing. Many mathematical problems cannot be formalised directly without first conjecturing a conclusion such as an explicit answer, or a specific bound. Since Large Language Models (LLMs) already struggle with autoformalisation, and the evaluation of their conjecturing ability is limited and often entangled within autoformalisation or proof, it is particularly challenging to understand its effect. To address this gap, we augment existing datasets to create ConjectureBench, and redesign the evaluation framework and metric specifically to measure the conjecturing capabilities of LLMs both as a distinct task and within the autoformalisation pipeline. Our evaluation of foundational models, including GPT-4.1 and DeepSeek-V3.1, reveals that their autoformalisation performance is substantially overestimated when the conjecture is accounted for during evaluation. However, the conjecture should not be assumed to be provided. We design an inference-time method, Lean-FIRe to improve conjecturing and autoformalisation, which, to the best of our knowledge, achieves the first successful end-to-end autoformalisation of 13 PutnamBench problems with GPT-4.1 and 7 with DeepSeek-V3.1. We demonstrate that while LLMs possess the requisite knowledge to generate accurate conjectures, improving autoformalisation performance requires treating conjecturing as an independent task, and investigating further how to correctly integrate it within autoformalisation. Finally, we provide forward-looking guidance to steer future research toward improving conjecturing, an overlooked step of formal mathematical reasoning.",https://www.semanticscholar.org/paper/f4d9b023987fac3f5a75259341da45edcbe47e34,,10.48550/arXiv.2510.11986,arXiv.org
6,Constructions in combinatorics via neural networks,Adam Zsolt Wagner,2021,"We demonstrate how by using a reinforcement learning algorithm, the deep cross-entropy method, one can find explicit constructions and counterexamples to several open conjectures in extremal combinatorics and graph theory. Amongst the conjectures we refute are a question of Brualdi and Cao about maximizing permanents of pattern avoiding matrices, and several problems related to the adjacency and distance eigenvalues of graphs.",https://arxiv.org/abs/2104.14516,52,10.48550/arXiv.2104.14516,arXiv
3,Discovering faster matrix multiplication algorithms with reinforcement learning,"Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Francisco J.R. Ruiz, Julian Schrittwieser, Grzegorz Swirszcz, David Silver, Demis Hassabis, Pushmeet Kohli",2022,"Improving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems—from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero for discovering efficient and provably correct algorithms for the multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a finite factor space. AlphaTensor discovered algorithms that outperform the state-of-the-art complexity for many matrix sizes. Particularly relevant is the case of 4 × 4 matrices in a finite field, where AlphaTensor’s algorithm improves on Strassen’s two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago. We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on specific hardware. Our results highlight AlphaTensor’s ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.",https://www.nature.com/articles/s41586-022-05172-4,N/A,10.1038/s41586-022-05172-4,Nature
discoveringnewtheore-2025,Discovering New Theorems via LLMs with In-Context Proof Learning in Lean,Kazumi Kasaura; Naoto Onda; Yuta Oriike; Masaya Taniguchi; Akiyoshi Sannai; Sho Sonoda,2025,"Large Language Models have demonstrated significant promise in formal theorem proving. However, previous works mainly focus on solving existing problems. In this paper, we focus on the ability of LLMs to find novel theorems. We propose Conjecturing-Proving Loop pipeline for automatically generating mathematical conjectures and proving them in Lean 4 format. A feature of our approach is that we generate and prove further conjectures with context including previously generated theorems and their proofs, which enables the generation of more difficult proofs by in-context learning of proof strategies without changing parameters of LLMs. We demonstrated that our framework rediscovered theorems with verification, which were published in past mathematical papers and have not yet formalized. Moreover, at least one of these theorems could not be proved by the LLM without in-context learning, even in natural language, which means that in-context learning was effective for neural theorem proving. The source code is available at https://github.com/auto-res/ConjecturingProvingLoop.",https://www.semanticscholar.org/paper/3613bc54e805538a908eb1f33da10c1df0b709c6,,10.48550/arXiv.2509.14274,arXiv.org
dynamicmodelsofneura-2024,Dynamic Models of Neural Population Dynamics,Han Hao; Kai Zhang; Momiao Xiong,2024,"The recent developments in artificial intelligence (AI) increase the hope that AI can provide a powerful tool to facilitate scientific discovery and to generate and validate new ideas for scientific research autonomously. Large Language Models (LLMs), such as ChatGPT4 have demonstrated remarkable capabilities in understanding and generating human-like text. Their potential extends beyond simple language tasks, offering transformative possibilities in scientific research of all fields. By leveraging vast amounts of data and advanced computational power, LLMs can assist researchers in generating novel ideas, automating routine tasks, and fostering interdisciplinary collaborations. On September 12, 2024, OpenAI released their updated generative artificial intelligence system called ChatGPTo1. This new AI system, built upon chain-of-thought and reinforcement learning, has greatly enhanced logical reasoning abilities and can effectively solve various complex problems from elementary-level mathematical problems to modern scientific research issues in physics, chemistry, and biology. Unlike previous LLMs in which logical reasoning and data analysis abilities are developed through training on actual data, ChatGPTo1 logical reasoning ability and capacity to generate new scientific ideas are primarily acquired through chain-of-thought processes and reinforcement learning rather than pre-training. To examine this, we specifically tested ChatGPTo1 current reasoning and scientific discovery capabilities by developing theoretically complex and quantitatively challenging scientific equations in various fields of neuroscience, such as dynamical systems, nonlinear dynamical systems, dynamical systems on differential manifolds, neural field theory, nonlinear divergence theorems, nonlinear heat conduction equations and Laplace equations and their extensions on differential manifolds, nonlinear statistical analysis methods, deep learning, and other topics involving multiple fields. The current large language models may illustrate a certain degree of general intelligence, even if fundamentally it may be different from human intelligence. However, it does not mean the current LLMs can fully apply such ability in practical applications or that their reasoning potential can be fully tapped. It is essential to explore specific pathways and methods to cultivate their potential for scientific discovery. To accomplish this, we consider how to integrate them with common search engines (such as Google) capabilities and ChatGPT4o cross-modal abilities to better understand new disciplines and scientific discoveries. To this point, the major shortcoming of ChatGPTo1 is that it is not an end-to-end scientific discovery method and lacks the ability to achieve full automation. It also lacks methods for image analysis and full-scale data analysis, making it difficult to use simulation and data analysis to evaluate and test proposed new theories and methods.",https://www.semanticscholar.org/paper/0ca7d0a8541404cbcad23fcaa3cb073e691caa81,,10.1101/2024.10.04.616750,bioRxiv
explainingpatternsin-2022,Explaining Patterns in Data with Language Models via Interpretable Autoprompting,Chandan Singh; John X. Morris; J. Aneja; Alexander M. Rush; Jianfeng Gao,2022,"Large language models (LLMs) have displayed an impressive ability to harness natural language to perform complex tasks. In this work, we explore whether we can leverage this learned ability to find and explain patterns in data. Specifically, given a pre-trained LLM and data examples, we introduce interpretable autoprompting (iPrompt), an algorithm that generates a natural-language string explaining the data. iPrompt iteratively alternates between generating explanations with an LLM and reranking them based on their performance when used as a prompt. Experiments on a wide range of datasets, from synthetic mathematics to natural-language understanding, show that iPrompt can yield meaningful insights by accurately finding groundtruth dataset descriptions. Moreover, the prompts produced by iPrompt are simultaneously human-interpretable and highly effective for generalization: on real-world sentiment classification datasets, iPrompt produces prompts that match or even improve upon human-written prompts for GPT-3. Finally, experiments with an fMRI dataset show the potential for iPrompt to aid in scientific discovery. All code for using the methods and data here is made available on Github.",https://www.semanticscholar.org/paper/224b8cd8c31cfa86c2a84bec3a65d9ba44f38280,,,
CEUR-WS:Vol-3432-paper5,Exploring Mathematical Conjecturing with Large Language Models,Moa Johansson; Nicholas Smallbone,2023,"The task of automating the discovery of mathematical conjectures has so far primarily been addressed in symbolic systems. However, a neuro-symbolic architecture seems like an excellent fit for this task. We can assign the generative task to a neural system without much risk, even if a few non-theorems slip through, the results are checked afterwards using a symbolic theorem prover or counter-example finder. In this initial case-study, we investigate the capabilities of GPT-3.5 and GPT-4 on this task. While results are mixed, we see potential in improving on the weaknesses of purely symbolic systems. A neuro-symbolic theory exploration system could, for instance, add some more variation in conjectures over purely symbolic systems while not missing obvious candidates.",https://ceur-ws.org/Vol-3432/paper5.pdf,16,,NeSy 2023 (CEUR-WS)
findinginductiveloop-2023,Finding Inductive Loop Invariants using Large Language Models,Adharsh Kamath; Aditya Senthilnathan; Saikat Chakraborty; Pantazis Deligiannis; Shuvendu K. Lahiri; Akash Lal; Aseem Rastogi; Subhajit Roy; Rahul Sharma,2023,"Loop invariants are fundamental to reasoning about programs with loops. They establish properties about a given loop's behavior. When they additionally are inductive, they become useful for the task of formal verification that seeks to establish strong mathematical guarantees about program's runtime behavior. The inductiveness ensures that the invariants can be checked locally without consulting the entire program, thus are indispensable artifacts in a formal proof of correctness. Finding inductive loop invariants is an undecidable problem, and despite a long history of research towards practical solutions, it remains far from a solved problem. This paper investigates the capabilities of the Large Language Models (LLMs) in offering a new solution towards this old, yet important problem. To that end, we first curate a dataset of verification problems on programs with loops. Next, we design a prompt for exploiting LLMs, obtaining inductive loop invariants, that are checked for correctness using sound symbolic tools. Finally, we explore the effectiveness of using an efficient combination of a symbolic tool and an LLM on our dataset and compare it against a purely symbolic baseline. Our results demonstrate that LLMs can help improve the state-of-the-art in automated program verification.",https://www.semanticscholar.org/paper/5824788bc6b355e1a655add875b100541aef4b59,34,10.48550/arXiv.2311.07948,arXiv.org
fromdatatophysicsana-2025,From Data to Physics: An Agentic Large Language Model Solves a Competitive Adsorption Puzzle.,Bingling Dai; Yuhang Song; Yue Zhan; Yibin Jiang; Cheng Wang,2025,"Scientific modeling often requires navigating a trade-off between physical interpretability and empirical accuracy-a task that can take weeks of iteration, especially in systems with partial observability, structural complexity, and experimental errors. Here, we show how an agentic reasoning-and-coding large language model (LLM), OpenAI o3, autonomously solved a modeling challenge in surface chemistry that puzzled us for months: quantifying the competitive adsorption of carboxylic acids on metal-organic layers (MOLs). With experimental data and a concise problem formulation, o3 rapidly formulated a physically grounded adsorption model, derived the mathematical equations, implemented the corresponding codes to fit the experimental data, revised its assumptions, and ultimately derived a competitive adsorption model with three parameters that matched experimental data across more than a dozen tested molecules. The resulting model-simple, mechanistically transparent, and quantitatively robust-incorporates both classical Langmuir competition and structural constraints such as site accessibility. Beyond addressing this particular challenge, our findings highlight a transformative shift in scientific methodology: from manual trial-and-error approaches to AI-driven hypothesis generation and model refinement. This represents a new paradigm in research, wherein language models surpass the traditional roles of machine learning in data analysis and computational support, actively participating in scientific reasoning and hypothesis development.",https://www.semanticscholar.org/paper/7235d20961089e9296b17465e718dafcb10c83d8,,10.1002/anie.202512151,Angewandte Chemie
fromwordmodelstoworl-2023,From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought,L. Wong; Gabriel Grand; Alexander K. Lew; Noah D. Goodman; Vikash K. Mansinghka; Jacob Andreas; J. Tenenbaum,2023,"How does language inform our downstream thinking? In particular, how do humans make meaning from language--and how can we leverage a theory of linguistic meaning to build machines that think in more human-like ways? In this paper, we propose rational meaning construction, a computational framework for language-informed thinking that combines neural language models with probabilistic models for rational inference. We frame linguistic meaning as a context-sensitive mapping from natural language into a probabilistic language of thought (PLoT)--a general-purpose symbolic substrate for generative world modeling. Our architecture integrates two computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language. We illustrate our framework through examples covering four core domains from cognitive science: probabilistic reasoning, logical and relational reasoning, visual and physical reasoning, and social reasoning. In each, we show that LLMs can generate context-sensitive translations that capture pragmatically-appropriate linguistic meanings, while Bayesian inference with the generated programs supports coherent and robust commonsense reasoning. We extend our framework to integrate cognitively-motivated symbolic modules (physics simulators, graphics engines, and planning algorithms) to provide a unified commonsense thinking interface from language. Finally, we explore how language can drive the construction of world models themselves. We hope this work will provide a roadmap towards cognitive models and AI systems that synthesize the insights of both modern and classical computational perspectives.",https://www.semanticscholar.org/paper/17d648a0a8ec8a9b30c7bedccbc38b3ed0a5cdda,125,10.48550/arXiv.2306.12672,arXiv.org
4,Generating conjectures on fundamental constants with the Ramanujan Machine,"Gal Raayoni, Shahar Gottlieb, Yahel Manor, George Pisha, Yoav Harris, Uri Mendlovic, Doron Haviv, Yaron Hadad, Ido Kaminer",2021,"Fundamental mathematical constants such as e and π are ubiquitous in diverse fields of science, from abstract mathematics and geometry to physics, biology and chemistry,. Nevertheless, for centuries new mathematical formulas relating fundamental constants have been scarce and usually discovered sporadically, , –. Such discoveries are often considered an act of mathematical ingenuity or profound intuition by great mathematicians such as Gauss and Ramanujan. Here we propose a systematic approach that leverages algorithms to discover mathematical formulas for fundamental constants and helps to reveal the underlying structure of the constants. We call this approach ‘the Ramanujan Machine’. Our algorithms find dozens of well known formulas as well as previously unknown ones, such as continued fraction representations of π, e, Catalan’s constant, and values of the Riemann zeta function. Several conjectures found by our algorithms were (in retrospect) simple to prove, whereas others remain as yet unproved. We present two algorithms that proved useful in finding conjectures: a variant of the meet-in-the-middle algorithm and a gradient descent optimization algorithm tailored to the recurrent structure of continued fractions. Both algorithms are based on matching numerical values; consequently, they conjecture formulas without providing proofs or requiring prior knowledge of the underlying mathematical structure, making this methodology complementary to automated theorem proving, , , , –. Our approach is especially attractive when applied to discover formulas for fundamental constants for which no mathematical structure is known, because it reverses the conventional usage of sequential logic in formal proofs. Instead, our work supports a different conceptual framework for research: computer algorithms use numerical data to unveil mathematical structures, thus trying to replace the mathematical intuition of great mathematicians and providing leads to further mathematical research.",https://www.nature.com/articles/s41586-021-03229-4,N/A,10.1038/s41586-021-03229-4,Nature
arXiv:2503.04772,Generating Millions Of Lean Theorems With Proofs By Exploring State Transition Graphs,David Yin; Jing Gao,2025,"Large Language Models (LLMs) have demonstrated significant potential in generating mathematical proofs. However, a persistent challenge is that LLMs occasionally make mistakes, while even a minor mistake can invalidate an entire proof. Proof assistants like Lean offer a great remedy. They are designed for verifying each step of a proof in a formal language, and in recent years researchers have created AI models to generate proofs in their languages. However, the scarcity of large-scale datasets of Lean proofs restrict the performance of such Automated Theorem Proving (ATP) models.
We developed LeanNavigator, a novel method for generating a large-scale dataset of Lean theorems and proofs by finding new ways to prove existing Lean theorems. By leveraging an interactive Lean client and an efficient method for proof step generation, LeanNavigator efficiently produces new theorems with corresponding proofs. Applying this approach to Mathlib4, we generated 4.7 million theorems totaling 1 billion tokens, surpassing previous datasets by more than an order of magnitude. Using this extensive dataset, we trained an AI model that outperforms the state-of-the-art ReProver model in theorem-proving tasks. These results confirm our hypothesis and demonstrate the critical role of large datasets in improving the performance of automated theorem provers.",https://arxiv.org/abs/2503.04772,3,10.48550/arXiv.2503.04772,arXiv
9,Generative Modeling for Mathematical Discovery,"Jordan S. Ellenberg, Cristofero S. Fraser-Taliente, Thomas R. Harvey, Karan Srivastava, Andrew V. Sutherland",2025,"We present a new implementation of the LLM-driven genetic algorithm {\it funsearch}, whose aim is to generate examples of interest to mathematicians and which has already had some success in problems in extremal combinatorics. Our implementation is designed to be useful in practice for working mathematicians; it does not require expertise in machine learning or access to high-performance computing resources. Applying {\it funsearch} to a new problem involves modifying a small segment of Python code and selecting a large language model (LLM) from one of many third-party providers. We benchmarked our implementation on three different problems, obtaining metrics that may inform applications of {\it funsearch} to new problems. Our results demonstrate that {\it funsearch} successfully learns in a variety of combinatorial and number-theoretic settings, and in some contexts learns principles that generalize beyond the problem originally trained on.",https://arxiv.org/abs/2503.11061,N/A,10.48550/arXiv.2503.11061,arXiv
hypothesissearchindu-2023,Hypothesis Search: Inductive Reasoning with Language Models,Ruocheng Wang; E. Zelikman; Gabriel Poesia; Yewen Pu; Nick Haber; Noah D. Goodman,2023,"Inductive reasoning is a core problem-solving capacity: humans can identify underlying principles from a few examples, which robustly generalize to novel scenarios. Recent work evaluates large language models (LLMs) on inductive reasoning tasks by directly prompting them yielding""in context learning.""This works well for straightforward inductive tasks but performs poorly on complex tasks such as the Abstraction and Reasoning Corpus (ARC). In this work, we propose to improve the inductive reasoning ability of LLMs by generating explicit hypotheses at multiple levels of abstraction: we prompt the LLM to propose multiple abstract hypotheses about the problem, in natural language, then implement the natural language hypotheses as concrete Python programs. These programs can be verified by running on observed examples and generalized to novel inputs. To reduce the hypothesis search space, we explore steps to filter the set of hypotheses to implement: we either ask the LLM to summarize them into a smaller set of hypotheses or ask human annotators to select a subset. We verify our pipeline's effectiveness on the ARC visual inductive reasoning benchmark, its variant 1D-ARC, string transformation dataset SyGuS, and list transformation dataset List Functions. On a random 100-problem subset of ARC, our automated pipeline using LLM summaries achieves 30% accuracy, outperforming the direct prompting baseline (accuracy of 17%). With the minimal human input of selecting from LLM-generated candidates, performance is boosted to 33%. Our ablations show that both abstract hypothesis generation and concrete program representations benefit LLMs on inductive reasoning tasks.",https://www.semanticscholar.org/paper/4cf527e9e0d68e3fc16d39fbcdb3869cd3ccf60f,148,10.48550/arXiv.2309.05660,International Conference on Learning Representations
iaginductionaugmente-2023,IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions,Zhebin Zhang; Xinyu Zhang; Yuanhang Ren; Saijiang Shi; Meng Han; Yongkang Wu; Ruofei Lai; Zhao Cao,2023,"Retrieval-Augmented Generation (RAG), by incorporating external knowledge with parametric memory of language models, has become the state-of-the-art architecture for open-domain QA tasks. However, common knowledge bases are inherently constrained by limited coverage and noisy information, making retrieval-based approaches inadequate to answer implicit reasoning questions. In this paper, we propose an Induction-Augmented Generation (IAG) framework that utilizes inductive knowledge along with the retrieved documents for implicit reasoning. We leverage large language models (LLMs) for deriving such knowledge via a novel prompting method based on inductive reasoning patterns. On top of this, we implement two versions of IAG named IAG-GPT and IAG-Student, respectively. IAG-GPT directly utilizes the knowledge generated by GPT-3 for answer prediction, while IAG-Student gets rid of dependencies on GPT service at inference time by incorporating a student inductor model. The inductor is firstly trained via knowledge distillation and further optimized by back-propagating the generator feedback via differentiable beam scores. Experimental results show that IAG outperforms RAG baselines as well as ChatGPT on two Open-Domain QA tasks. Notably, our best models have won the first place in the official leaderboards of CSQA2.0 (since Nov 1, 2022) and StrategyQA (since Jan 8, 2023).",https://www.semanticscholar.org/paper/bd1ef429956cea3542c14006df67e890cb57a80b,24,10.48550/arXiv.2311.18397,Conference on Empirical Methods in Natural Language Processing
integratinglargelang-2023,Integrating Large Language Model for Improved Causal Discovery,Taiyu Ban; Lyuzhou Chen; Derui Lyu; Xiangyu Wang; Qinrui Zhu; Qiang Tu; Huanhuan Chen,2023,"Recovering the structure of causal graphical models from observational data is an essential yet challenging task for causal discovery in scientific scenarios. Domain-specific causal discovery usually relies on expert validation or prior analysis to improve the reliability of recovered causality, which is yet limited by the scarcity of expert resources. Recently, large language models (LLM) have been used for causal analysis across various domain-specific scenarios, suggesting its potential as autonomous expert roles in guiding data-based structure learning. However, integrating LLMs into causal discovery faces challenges due to inaccuracies in LLM-based reasoning on revealing the actual causal structure. To address this challenge, we propose an error-tolerant LLM-driven causal discovery framework. The error-tolerant mechanism is designed three-fold with sufficient consideration on potential inaccuracies. In the LLM-based reasoning process, an accuracy-oriented prompting strategy restricts causal analysis to a reliable range. Next, a knowledge-to-structure transition aligns LLM-derived causal statements with structural causal interactions. In the structure learning process, the goodness-of-fit to data and adherence to LLM-derived priors are balanced to further address prior inaccuracies. Evaluation of eight real-world causal structures demonstrates the efficacy of our LLM-driven approach in improving data-based causal discovery, along with its robustness to inaccurate LLM-derived priors.",https://www.semanticscholar.org/paper/37a25ec621139e98498252874b142c6ef3730e2a,58,10.1109/TAI.2025.3560927,IEEE Transactions on Artificial Intelligence
isknowledgealllargel-2023,Is Knowledge All Large Language Models Needed for Causal Reasoning?,Hengrui Cai; Shengjie Liu; Rui Song,2023,"This paper explores the causal reasoning of large language models (LLMs) to enhance their interpretability and reliability in advancing artificial intelligence. Despite the proficiency of LLMs in a range of tasks, their potential for understanding causality requires further exploration. We propose a novel causal attribution model that utilizes ``do-operators""for constructing counterfactual scenarios, allowing us to systematically quantify the influence of input numerical data and LLMs' pre-existing knowledge on their causal reasoning processes. Our newly developed experimental setup assesses LLMs' reliance on contextual information and inherent knowledge across various domains. Our evaluation reveals that LLMs' causal reasoning ability mainly depends on the context and domain-specific knowledge provided. In the absence of such knowledge, LLMs can still maintain a degree of causal reasoning using the available numerical data, albeit with limitations in the calculations. This motivates the proposed fine-tuned LLM for pairwise causal discovery, effectively leveraging both knowledge and numerical information.",https://www.semanticscholar.org/paper/df0db04d870e1666a64a9c92688419e7628423e5,19,10.48550/arXiv.2401.00139,arXiv.org
languagemodelingforf-2020,Language Modeling for Formal Mathematics,M. Rabe; Dennis Lee; Kshitij Bansal; Christian Szegedy,2020,"We examine whether language modeling applied to mathematical formulas enables logical reasoning. We suggest several logical reasoning tasks that can be used to evaluate language models trained on formal mathematical statements, such as type inference, suggesting missing assumptions and completing equalities. To train language models for formal mathematics, we propose a novel skip-tree task, which outperforms standard language modeling tasks on our reasoning benchmarks. We also analyze the models' ability to formulate new conjectures by measuring how often the predictions that do not fit the ground truth or any training data turn out to be true and useful statements.",https://www.semanticscholar.org/paper/f672ae886ef032204f09f6da043890850b2e59cf,2,,arXiv.org
largelanguagemodelsf-2023,Large Language Models for Automated Open-domain Scientific Hypotheses Discovery,Zonglin Yang; Xinya Du; Junxian Li; Jie Zheng; Soujanya Poria; E. Cambria,2023,"Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are carefully manually handpicked sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses are mostly commonsense knowledge, making the task less challenging. In this work, we tackle these problems by proposing the first dataset for social science academic hypotheses discovery, with the final goal to create systems that automatically generate valid, novel, and helpful scientific hypotheses, given only a pile of raw web corpus. Unlike previous settings, the new dataset requires (1) using open-domain data (raw web corpus) as observations; and (2) proposing hypotheses even new to humanity. A multi-module framework is developed for the task, including three different feedback mechanisms to boost performance, which exhibits superior performance in terms of both GPT-4 based and expert-based evaluation. To the best of our knowledge, this is the first work showing that LLMs are able to generate novel (''not existing in literature'') and valid (''reflecting reality'') scientific hypotheses.",https://www.semanticscholar.org/paper/5aea5c8b536380c5ad1d42108c2c6767622318ee,79,10.48550/arXiv.2309.02726,Annual Meeting of the Association for Computational Linguistics
largelanguagemodelsf-2024,Large language models for automatic equation discovery of nonlinear dynamics,Mengge Du; Yuntian Chen; Zhongzheng Wang; Longfeng Nie; Dong-juan Zhang,2024,"Equation discovery aims to directly extract physical laws from data and has emerged as a pivotal research domain in nonlinear systems. Previous methods based on symbolic mathematics have achieved substantial advancements, but often require handcrafted representation rules and complex optimization algorithms. In this paper, we introduce a novel framework that utilizes natural language-based prompts to guide large language models (LLMs) in automatically extracting governing equations from data. Specifically, we first utilize the generation capability of LLMs to generate diverse candidate equations in string form and then evaluate the generated equations based on observations. The best equations are preserved and further refined iteratively using the reasoning capacity of LLMs. We propose two alternately iterated strategies to collaboratively optimize the generated equations. The first strategy uses LLMs as a black-box optimizer to achieve equation self-improvement based on historical samples and their performance. The second strategy instructs LLMs to perform evolutionary operations for a global search. Experiments are conducted on various nonlinear systems described by partial differential equations, including the Burgers equation, the Chafee–Infante equation, and the Navier–Stokes equation. The results demonstrate that our framework can discover correct equations that reveal the underlying physical laws. Further comparisons with state-of-the-art models on extensive ordinary differential equations showcase that the equations discovered by our framework possess physical meaning and better generalization capability on unseen data.",https://www.semanticscholar.org/paper/d7b609fca92dbd864f31b6de571ab8a4ed0ed1c4,34,10.1063/5.0224297,The Physics of Fluids
leanconjecturerautom-2025,LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving,Naoto Onda; Kazumi Kasaura; Yuta Oriike; Masaya Taniguchi; Akiyoshi Sannai; Sho Sonoda,2025,"We introduce LeanConjecturer, a pipeline for automatically generating university-level mathematical conjectures in Lean 4 using Large Language Models (LLMs). Our hybrid approach combines rule-based context extraction with LLM-based theorem statement generation, addressing the data scarcity challenge in formal theorem proving. Through iterative generation and evaluation, LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with 3,776 identified as syntactically valid and non-trivial, that is, cannot be proven by \texttt{aesop} tactic. We demonstrate the utility of these generated conjectures for reinforcement learning through Group Relative Policy Optimization (GRPO), showing that targeted training on domain-specific conjectures can enhance theorem proving capabilities. Our approach generates 103.25 novel conjectures per seed file on average, providing a scalable solution for creating training data for theorem proving systems. Our system successfully verified several non-trivial theorems in topology, including properties of semi-open, alpha-open, and pre-open sets, demonstrating its potential for mathematical discovery beyond simple variations of existing results.",https://www.semanticscholar.org/paper/6b7806c144d741ed841debb9875a64d852d89765,,10.48550/arXiv.2506.22005,arXiv.org
openreview:EBa52sye9K,Learning to Disprove: Formal Counterexample Generation with Large Language Models,"Zenan Li, Zenan_Li, Zhaoyu Li, Kaiyu Yang, Xiaoxing Ma, Zhendong Su",2026,"Mathematical reasoning demands two critical, complementary skills: constructing rigorous proofs for true statements and discovering counterexamples that disprove false ones. However, current AI efforts in mathematics focus almost exclusively on proof construction, often neglecting the equally important task of finding counterexamples. In this paper, we address this gap by fine-tuning large language models (LLMs) to reason about and generate counterexamples. We formalize this task as formal counterexample generation, which requires LLMs not only to propose candidate counterexamples but also to produce formal proofs that can be automatically verified in the Lean 4 theorem prover. To enable effective learning, we introduce a symbolic mutation strategy that synthesizes diverse training data by systematically extracting theorems and discarding selected hypotheses, thereby producing diverse counterexample instances. Together with curated datasets, this strategy enables a multi-reward expert iteration framework that substantially enhances both the effectiveness and efficiency of training LLMs for counterexample generation and theorem proving. Experiments on three newly collected benchmarks validate the advantages of our approach, showing that the mutation strategy and training framework yield significant performance gains.",https://openreview.net/pdf?id=EBa52sye9K,0,,ICLR 2026 (under review)
legoproverneuraltheo-2023,LEGO-Prover: Neural Theorem Proving with Growing Libraries,Huajian Xin; Haiming Wang; Chuanyang Zheng; Lin Li; Zhengying Liu; Qingxing Cao; Yinya Huang; Jing Xiong; Han Shi; Enze Xie; Jian Yin; Zhenguo Li; Xiaodan Liang; Heng Liao,2023,"Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by prompting an LLM) to enrich the library on another scale. Modular and reusable skills are constantly added to the library to enable tackling increasingly intricate mathematical problems. Moreover, the learned library further bridges the gap between human proofs and formal proofs by making it easier to impute missing steps. LEGO-Prover advances the state-of-the-art pass rate on miniF2F-valid (48.0% to 57.0%) and miniF2F-test (45.5% to 47.1%). During the proving process, LEGO-Prover also manages to generate over 20,000 skills (theorems/lemmas) and adds them to the growing library. Our ablation study indicates that these newly added skills are indeed helpful for proving theorems, resulting in an improvement from a success rate of 47.1% to 50.4%. We also release our code and all the generated skills.",https://www.semanticscholar.org/paper/f8b5ee53c3410f20049e7def47bd52403fa388e3,100,10.48550/arXiv.2310.00656,International Conference on Learning Representations
lemmanaidneurosymbol-2025,Lemmanaid: Neuro-Symbolic Lemma Conjecturing,Yousef Alhessi; S'olr'un Halla Einarsd'ottir; George Granberry; Emily First; Moa Johansson; Sorin Lerner; Nicholas Smallbone,2025,"Automatically conjecturing useful, interesting and novel lemmas would greatly improve automated reasoning tools and lower the bar for formalizing mathematics in proof assistants. It is however a very challenging task for both neural and symbolic approaches. We present the first steps towards a practical neuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language Models (LLMs) and symbolic methods, and evaluate it on proof libraries for the Isabelle proof assistant. We train an LLM to generate lemma templates that describe the shape of a lemma, and use symbolic methods to fill in the details. We compare Lemmanaid against an LLM trained to generate complete lemma statements as well as previous fully symbolic conjecturing methods. Lemmanaid outperforms both neural and symbolic methods on test sets from Isabelle's HOL library and from its Archive of Formal Proofs, discovering between 29-39.5% of the gold standard human written lemmas. This is 8-15% more lemmas than the neural-only method. By leveraging the best of both symbolic and neural methods we can generate useful lemmas for a wide range of input domains, facilitating computer-assisted theory development and formalization.",https://www.semanticscholar.org/paper/498079c9288e4b47a3c1056a82bb546113459b70,2,10.48550/arXiv.2504.04942,arXiv.org
literaturebasedautom-2018,Literature-based automated discovery of tumor suppressor p53 phosphorylation and inhibition by NEK2,Byung-Kwon Choi; Tajhal Dayaram; Neha Parikh; Angela D. Wilkins; Meena Nagarajan; Ilya B. Novikov; Benjamin J. Bachman; S. Jung; P. Haas; J. Labrie; C. Pickering; Anbu K. Adikesavan; Sam Regenbogen; Linda Kato; A. Lelescu; Christie Buchovecky; Houyin Zhang; Sheng Hua Bao; Stephen K. Boyer; G. Weber; K. Scott; Ying Chen; Scott Spangler; L. Donehower; O. Lichtarge,2018,"Significance We adapted natural language processing to the biological literature and demonstrated end-to-end automated knowledge discovery by exploring subtle word connections. General text mining scanned 21 million publication abstracts and selected a reliable 130,000 from which hypothesis generation algorithms predicted kinases not known to phosphorylate p53, but likely to do so. Six of these p53 kinase candidates passed experimental validation. Among them NEK2 was examined in depth and shown to repress p53 and promote cell division. This work demonstrates the possibility of integrating a vast corpora of written knowledge to compute valuable hypotheses that will often test true and fuel discovery. Scientific progress depends on formulating testable hypotheses informed by the literature. In many domains, however, this model is strained because the number of research papers exceeds human readability. Here, we developed computational assistance to analyze the biomedical literature by reading PubMed abstracts to suggest new hypotheses. The approach was tested experimentally on the tumor suppressor p53 by ranking its most likely kinases, based on all available abstracts. Many of the best-ranked kinases were found to bind and phosphorylate p53 (P value = 0.005), suggesting six likely p53 kinases so far. One of these, NEK2, was studied in detail. A known mitosis promoter, NEK2 was shown to phosphorylate p53 at Ser315 in vitro and in vivo and to functionally inhibit p53. These bona fide validations of text-based predictions of p53 phosphorylation, and the discovery of an inhibitory p53 kinase of pharmaceutical interest, suggest that automated reasoning using a large body of literature can generate valuable molecular hypotheses and has the potential to accelerate scientific discovery.",https://www.semanticscholar.org/paper/51f497e9b2f6682e5c455cacee4bd0aeb7f810a7,45,10.1073/pnas.1806643115,Proceedings of the National Academy of Sciences of the United States of America
llmsrscientificequat-2024,LLM-SR: Scientific Equation Discovery via Programming with Large Language Models,Parshin Shojaee; Kazem Meidani; Shashank Gupta; A. Farimani; Chandan K. Reddy,2024,"Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines. However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely large combinatorial hypothesis spaces. Current methods of equation discovery, commonly known as symbolic regression techniques, largely focus on extracting equations from data alone, often neglecting the domain-specific prior knowledge that scientists typically depend on. They also employ limited representations such as expression trees, constraining the search space and expressiveness of equations. To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data. Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs. The LLM iteratively proposes new equation skeleton hypotheses, drawing from its domain knowledge, which are then optimized against data to estimate parameters. We evaluate LLM-SR on four benchmark problems across diverse scientific domains (e.g., physics, biology), which we carefully designed to simulate the discovery process and prevent LLM recitation. Our results demonstrate that LLM-SR discovers physically accurate equations that significantly outperform state-of-the-art symbolic regression baselines, particularly in out-of-domain test settings. We also show that LLM-SR's incorporation of scientific priors enables more efficient equation space exploration than the baselines. Code and data are available: https://github.com/deep-symbolic-mathematics/LLM-SR",https://www.semanticscholar.org/paper/860ba78f9789bbfc99c299b18558ca19430d8fea,51,10.48550/arXiv.2404.18400,International Conference on Learning Representations
llmsrbenchanewbenchm-2025,LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models,Parshin Shojaee; Ngoc-Hieu Nguyen; Kazem Meidani; A. Farimani; Khoa D. Doan; Chandan K. Reddy,2025,"Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy. These findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.",https://www.semanticscholar.org/paper/79d455c55401734971aba42a76204f973980ed04,21,10.48550/arXiv.2504.10415,International Conference on Machine Learning
llm4laserlargelangua-2021,LLM4Laser: Large Language Models Automate the Design of Lasers,Renjie Li; Ceyao Zhang; Sixuan Mao; Hai Huang; Mou Zhong; Yiou Cui; Xiyuan Zhou; F. Yin; Zhaoyu Zhang,2021,"With the rapid evolution of global autonomous driving technology, the demand for its core sensing hardware, Light Detection and Ranging (LiDAR), is escalating. As the light source part of the LiDAR system, lasers, particularly the cutting-edge Photonic Crystal Surface Emitting Lasers (PCSEL), have correspondingly attracted extensive research attention. The conventional manual design and optimization of PCSEL typically require expertise in semiconductor physics and months of dedicated effort to achieve satisfactory results. While AI-driven approaches can expedite this process, laser designers still need to invest time in learning the AI algorithms involved. Meanwhile Large Language Models (LLMs), leveraging their powerful reasoning abilities, can effectively comprehend natural language and provide constructive feedback in multi-turn dialogues. They have already demonstrated potential to assist humans in scientific fields such as robotics design and chemical discovery. A question naturally arises is: Can LLMs transform the lasers design process? This paper proposes a novel human-AI co-design paradigm to show that LLMs can guide the laser design and optimization process both conceptually and technically. Specifically, by simply having conversations, GPT assisted us with writing both Finite Difference Time Domain (FDTD) simulation code and deep reinforcement learning (RL) code to acquire the optimized PCSEL solution, spanning from the proposition of ideas to the realization of algorithms. Given that GPT will perform better when given detailed and specific prompts, we break down the PCSEL design problem into a series of sub-problems and converse with GPT by posing open-ended heuristic questions rather than definitive commands. We achieved a significant milestone towards self-driving laboratories, that is, a fully automated AI-driven pipeline, for laser design and production.",https://www.semanticscholar.org/paper/3d76521a6d12bf167cc0ecbb6396ccddd40a385c,3,,
mathpvsalargelanguag-2023,math-PVS: A Large Language Model Framework to Map Scientific Publications to PVS Theories,Hassen Saidi; Susmit Jha; T. Sahai,2023,"As artificial intelligence (AI) gains greater adoption in a wide variety of applications, it has immense potential to contribute to mathematical discovery, by guiding conjecture generation, constructing counterexamples, assisting in formalizing mathematics, and discovering connections between different mathematical areas, to name a few. While prior work has leveraged computers for exhaustive mathematical proof search, recent efforts based on large language models (LLMs) aspire to position computing platforms as co-contributors in the mathematical research process. Despite their current limitations in logic and mathematical tasks, there is growing interest in melding theorem proving systems with foundation models. This work investigates the applicability of LLMs in formalizing advanced mathematical concepts and proposes a framework that can critically review and check mathematical reasoning in research papers. Given the noted reasoning shortcomings of LLMs, our approach synergizes the capabilities of proof assistants, specifically PVS, with LLMs, enabling a bridge between textual descriptions in academic papers and formal specifications in PVS. By harnessing the PVS environment, coupled with data ingestion and conversion mechanisms, we envision an automated process, called \emph{math-PVS}, to extract and formalize mathematical theorems from research papers, offering an innovative tool for academic review and discovery.",https://www.semanticscholar.org/paper/4a830a6cba4ec8c87c10348955b6bb633f401c0b,,10.48550/arXiv.2310.17064,arXiv.org
mathematicaldiscover-2023,Mathematical discoveries from program search with large language models,Bernardino Romera-Paredes; M. Barekatain; Alexander Novikov; Matej Balog; M. P. Kumar; Emilien Dupont; Francisco J. R. Ruiz; J. Ellenberg; Pengming Wang; Omar Fawzi; Pushmeet Kohli; Alhussein Fawzi; Josh Grochow; Andrea Lodi; Jean-Baptiste Mouret; Talia Ringer; Tao Yu,2023,"Large language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements1,2. This hinders the use of current large models in scientific discovery. Here we introduce FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. We demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches3. Applying FunSearch to a central problem in extremal combinatorics—the cap set problem—we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. We showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications. FunSearch makes discoveries in established open problems using large language models by searching for programs describing how to solve a problem, rather than what the solution is.",https://www.semanticscholar.org/paper/d32ba88571141ed0ebe7aeefbaa4ccaf8cda7be3,574,10.1038/s41586-023-06924-6,Nature
1,Mathematical discoveries from program search with large language models,"Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J.R. Ruiz, Jordan S. Ellenberg, Pengming Wang, Omar Fawzi, Pushmeet Kohli, Alhussein Fawzi",2024,"Large language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements,. This hinders the use of current large models in scientific discovery. Here we introduce FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. We demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches. Applying FunSearch to a central problem in extremal combinatorics—the cap set problem—we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. We showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications.",https://www.nature.com/articles/s41586-023-06924-6,N/A,10.1038/s41586-023-06924-6,Nature
mathematicalexplorat-2025,Mathematical exploration and discovery at scale,Bogdan Georgiev; Javier G'omez-Serrano; Terence Tao; Adam Zsolt Wagner,2025,"AlphaEvolve is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems. To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights. These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.",https://www.semanticscholar.org/paper/bcd109c090c071a28b668bdd81f075b076fed854,6,10.48550/arXiv.2511.02864,arXiv.org
mathematicalreasonin-2020,Mathematical Reasoning via Self-supervised Skip-tree Training,M. Rabe; Dennis Lee; Kshitij Bansal; Christian Szegedy,2020,"We examine whether self-supervised language modeling applied to mathematicalformulas enables logical reasoning. We suggest several logical reasoning tasks thatcan be used to evaluate language models trained on formal mathematical statements,such as type inference, suggesting missing assumptions and completing equalities.To train language models for formal mathematics, we propose a novel skip-treetask. We find that models trained on the skip-tree task show surprisingly strongmathematical reasoning abilities, and outperform models trained on standard skip-sequence tasks. We also analyze the models’ ability to formulate new conjecturesby measuring how often the predictions are provable and useful in other proofs.",https://www.semanticscholar.org/paper/45bb43cdc35324fea4350ed335c500d4a5fd6ef5,63,,International Conference on Learning Representations
7,Mining Math Conjectures from LLMs: A Pruning Approach,"Jake Chuharski, Elias Rojas Collins, Mark Meringolo",2024,"We present a novel approach to generating mathematical conjectures using Large Language Models (LLMs). Focusing on the solubilizer, a relatively recent construct in group theory, we demonstrate how LLMs such as ChatGPT, Gemini, and Claude can be leveraged to generate conjectures. These conjectures are pruned by allowing the LLMs to generate counterexamples. Our results indicate that LLMs are capable of producing original conjectures that, while not groundbreaking, are either plausible or falsifiable via counterexamples, though they exhibit limitations in code execution.",https://arxiv.org/abs/2412.16177,N/A,10.48550/arXiv.2412.16177,arXiv / NeurIPS 2024 MATH-AI Workshop
montecarlothoughtsea-2023,Monte Carlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design,Henry W. Sprueill; Carl N. Edwards; Mariefel V. Olarte; Udishnu Sanyal; Heng Ji; Sutanay Choudhury,2023,"Discovering novel catalysts requires complex reasoning involving multiple chemical properties and resultant trade-offs, leading to a combinatorial growth in the search space. While large language models (LLM) have demonstrated novel capabilities for chemistry through complex instruction following capabilities and high quality reasoning, a goal-driven combinatorial search using LLMs has not been explored in detail. In this work, we present a Monte Carlo Tree Search-based approach that improves beyond state-of-the-art chain-of-thought prompting variants to augment scientific reasoning. We introduce two new reasoning datasets: 1) a curation of computational chemistry simulations, and 2) diverse questions written by catalysis researchers for reasoning about novel chemical conversion processes. We improve over the best baseline by 25.8\% and find that our approach can augment scientist's reasoning and discovery process with novel insights.",https://www.semanticscholar.org/paper/2129c6edc2593bf4adb5bc2772fdb042bdf14070,13,10.48550/arXiv.2310.14420,Conference on Empirical Methods in Natural Language Processing
onllmbasedscientific-2025,On LLM-Based Scientific Inductive Reasoning Beyond Equations,Brian S. Lin; Jiaxin Yuan; Zihan Zhou; Shouli Wang; Shuo Wang; Cunliang Kong; Qi Shi; Yuxuan Li; Liner Yang; Zhiyuan Liu; Maosong Sun,2025,"As large language models (LLMs) increasingly exhibit human-like capabilities, a fundamental question emerges: How can we enable LLMs to learn the underlying patterns from limited examples in entirely novel environments and apply them effectively? This question is central to the ability of LLMs in inductive reasoning. Existing research on LLM-based inductive reasoning can be broadly categorized based on whether the underlying rules are expressible via explicit mathematical equations. However, many recent studies in the beyond-equations category have emphasized rule design without grounding them in specific scenarios. Inspired by the parallels between inductive reasoning and human scientific discovery, we propose the task of LLM-Based Scientific Inductive Reasoning Beyond Equations and introduce a new benchmark, SIRBench-V1, to evaluate the inductive reasoning abilities of LLMs in scientific settings. Our experimental results show that current LLMs still struggle with this task, underscoring its difficulty and the need for further advancement in this area.",https://www.semanticscholar.org/paper/762448b51173b3e4082408cde863d16baed51ee7,,10.48550/arXiv.2509.16226,Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing
proposingandsolvingo-2024,Proposing and solving olympiad geometry with guided tree search,Chi Zhang; Jiajun Song; Siyu Li; Yitao Liang; Yuxi Ma; Wei Wang; Yixin Zhu; Song-Chun Zhu,2024,"Mathematics olympiads are prestigious competitions, with problem proposing and solving highly honored. Building artificial intelligence that proposes and solves olympiads presents an unresolved challenge in automated theorem discovery and proving, especially in geometry for its combination of numerical and spatial elements. We introduce TongGeometry, a Euclidean geometry system supporting tree-search-based guided problem proposing and solving. The efficient geometry system establishes the most extensive repository of geometry theorems to date: within the same computational budget as the existing state-of-the-art, TongGeometry discovers 6.7 billion geometry theorems requiring auxiliary constructions, including 4.1 billion exhibiting geometric symmetry. Among them, 10 theorems were proposed to regional mathematical olympiads with 3 of TongGeometry's proposals selected in real competitions, earning spots in a national team qualifying exam or a top civil olympiad in China and the US. Guided by fine-tuned large language models, TongGeometry solved all International Mathematical Olympiad geometry in IMO-AG-30, outperforming gold medalists for the first time. It also surpasses the existing state-of-the-art across a broader spectrum of olympiad-level problems. The full capabilities of the system can be utilized on a consumer-grade machine, making the model more accessible and fostering widespread democratization of its use. By analogy, unlike existing systems that merely solve problems like students, TongGeometry acts like a geometry coach, discovering, presenting, and proving theorems.",https://www.semanticscholar.org/paper/a89fe3c6749c79354b30a154c6298a7ff2bec9d6,11,10.48550/arXiv.2412.10673,arXiv.org
arXiv:2509.18057,Reinforced Generation of Combinatorial Structures: Hardness of Approximation,Ansh Nagda; Prabhakar Raghavan; Abhradeep Thakurta,2025,"Can AI based methods help us make advances in complexity theory? We provide evidence towards answering this in the affirmative, using AlphaEvolve (an LLM code mutation agent) to obtain new results in three settings: a) We improve a recent result of Kunisky and Yu to obtain near-optimal upper and (conditional) lower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on random 3- and 4-regular graphs. Our improved lower bounds are obtained by constructing nearly extremal Ramanujan graphs on as many as  vertices, and our upper bounds are obtained via analytical arguments. b) We obtain new inapproximability results for MAX-4-CUT and MAX-3-CUT, proving that it is NP-hard to approximate them within factors of  and  respectively, using AlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves upon the SOTA of , and our MAX-3-CUT result improves on the current best gadget-based inapproximability result of , but falls short of the SOTA of  that relies on a custom PCP (rather than a reduction from ``standard'' H{\aa}stad-style PCPs). c) Inapproximability for the metric Traveling Salesman Problem (TSP): We show that it is NP-hard to approximate the minimum cost tour within a factor of  using AlphaEvolve to discover a new gadget, thus improving the SOTA of . Along the way, we provide new modular soundness and completeness arguments that can be of independent interest. A key technical challenge we faced: verifying a candidate construction produced by AlphaEvolve is costly (sometimes requiring time exponential in the size of the construction). We used AlphaEvolve itself to evolve the verification procedure to be faster (sometimes by  for our gadgets). Our results suggest that gadget based proofs would benefit from a pass through AI-based tools to obtain stronger results.",https://arxiv.org/abs/2509.18057,0,10.48550/arXiv.2509.18057,arXiv
sciagentsautomatings-2024,SciAgents: Automating Scientific Discovery Through Bioinspired Multi‐Agent Intelligent Graph Reasoning,Alireza Ghafarollahi; Markus J. Buehler,2024,"A key challenge in artificial intelligence (AI) is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, SciAgents, an approach that leverages three core concepts is presented: (1) large‐scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi‐agent systems with in‐situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses human research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the system yields material discoveries, critiques and improves existing hypotheses, retrieves up‐to‐date data about existing research, and highlights strengths and limitations. This is achieved by harnessing a “swarm of intelligence” similar to biological systems, providing new avenues for discovery. How this model accelerates the development of advanced materials by unlocking Nature's design principles, resulting in a new biocomposite with enhanced mechanical properties and improved sustainability through energy‐efficient production is shown.",https://www.semanticscholar.org/paper/dbbcdb281ed6aa646af0402172cf8a7cfda85d5c,80,10.1002/adma.202413523,Advances in Materials
arXiv:2502.00212,STP: Self-play LLM Theorem Provers with Iterative Conjecturing and Proving,K. Dong; H. Wang; N. Shu; et al.,2025,"A fundamental challenge in formal theorem proving by LLMs is the lack of high-quality training data. Although reinforcement learning or expert iteration partially mitigates this issue by alternating between LLM generating proofs and finetuning them on correctly generated ones, performance quickly plateaus due to the scarcity of correct proofs (sparse rewards). To keep improving the models with limited data, we draw inspiration from mathematicians, who continuously develop new results, partly by proposing novel conjectures or exercises (which are often variants of known results) and attempting to solve them. We design the Self-play Theorem Prover (STP) that simultaneously takes on two roles, conjecturer and prover, each providing training signals to the other. The conjecturer is trained iteratively on previously generated conjectures that are barely provable by the current prover, which incentivizes it to generate increasingly challenging conjectures over time. The prover attempts to prove the conjectures with standard expert iteration. We evaluate STP with both Lean and Isabelle formal versifiers. With 19.8 billion tokens generated during the training in Lean, STP proves 26.3% of the statements in the LeanWorkbook dataset, doubling the previous best result of 13.2% achieved through expert iteration. The final model achieves state-of-the-art performance among whole-proof generation methods on miniF2F-test (61.1%, pass@3200), Proofnet-test (23.1%, pass@3200) and PutnamBench (8/644, pass@64).",https://arxiv.org/abs/2502.00212,39,10.48550/arXiv.2502.00212,ICML 2025
selfreflectinglargel-2025,Self-reflecting Large Language Models: A Hegelian Dialectical Approach,Sara Abdali; Can Goksen; Saeed Amizadeh; K. Koishida,2025,"Investigating NLP through a philosophical lens has recently caught researchers'eyes, as it bridges computational methods with classical schools of philosophy. This paper introduces a philosophical framework inspired by the Hegelian Dialectic to enable LLMs'self-reflection, utilizing a self-dialectical approach to emulate internal critiques and synthesize new scientific ideas (spanning domains such as mathematics, physics, and more). Additionally, we explore the effect of generation temperature in LLMs by introducing a dynamic annealing approach, which encourages creativity in the early stages and gradually focuses on refinement and nuance, as well as a constant-temperature strategy. Furthermore, we implement a Multi-Agent Majority Voting (MAMV) strategy to assess the validity and novelty of the generated ideas, which proves useful in the absence of domain experts. We also evaluate the effectiveness of our method in generating novel scientific ideas and improving LLMs'reasoning capabilities. Our experiments demonstrate promising results in ideation, along with significant improvements in mathematical and symbolic reasoning.",https://www.semanticscholar.org/paper/45c0cc80a04a839489084e3eed81704adacab413,,10.48550/arXiv.2501.14917,arXiv.org
sentimentawarestockp-2025,Sentiment-Aware Stock Price Prediction with Transformer and LLM-Generated Formulaic Alpha,Qizhao Chen; Hiroaki Kawashima,2025,"Traditionally, traders and quantitative analysts address alpha decay by manually crafting formulaic alphas, mathematical expressions that identify patterns or signals in financial data, through domain expertise and trial-and-error. This process is often time-consuming and difficult to scale. With recent advances in large language models (LLMs), it is now possible to automate the generation of such alphas by leveraging the reasoning capabilities of LLMs. This paper introduces a novel framework that integrates a prompt-based LLM with a Transformer model for stock price prediction. The LLM first generates diverse and adaptive alphas using structured inputs such as historical stock features (Close, Open, High, Low, Volume), technical indicators, sentiment scores of both target and related companies. These alphas, instead of being used directly for trading, are treated as high-level features that capture complex dependencies within the financial data. To evaluate the effectiveness of these LLM-generated formulaic alphas, the alpha features are then fed into prediction models such as Transformer, LSTM, TCN, SVR, and Random Forest to forecast future stock prices. Experimental results demonstrate that the LLM-generated alphas significantly improve predictive accuracy. Moreover, the accompanying natural language reasoning provided by the LLM enhances the interpretability and transparency of the predictions, supporting more informed financial decision-making.",https://www.semanticscholar.org/paper/c083140db755fc1030da1b4af325017e45b680c5,3,10.48550/arXiv.2508.04975,arXiv.org
shinkaevolvetowardso-2025,ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution,R. Lange; Yuki Imajuku; Edoardo Cetin,2025,"We introduce ShinkaEvolve: a new open-source framework leveraging large language models (LLMs) to advance scientific discovery with state-of-the-art performance and unprecedented efficiency. Recent advances in scaling inference time compute of LLMs have enabled significant progress in generalized scientific discovery. These approaches rely on evolutionary agentic harnesses that leverage LLMs as mutation operators to generate candidate solutions. However, current code evolution methods suffer from critical limitations: they are sample inefficient, requiring thousands of samples to identify effective solutions, and remain closed-source, hindering broad adoption and extension. ShinkaEvolve addresses these limitations, introducing three key innovations: a parent sampling technique balancing exploration and exploitation, code novelty rejection-sampling for efficient search space exploration, and a bandit-based LLM ensemble selection strategy. We evaluate ShinkaEvolve across diverse tasks, demonstrating consistent improvements in sample efficiency and solution quality. ShinkaEvolve discovers a new state-of-the-art circle packing solution using only 150 samples, designs high-performing agentic harnesses for AIME mathematical reasoning tasks, identifies improvements to ALE-Bench competitive programming solutions, and discovers novel mixture-of-expert load balancing loss functions that illuminate the space of optimization strategies. Our results demonstrate that ShinkaEvolve achieves broad applicability with exceptional sample efficiency. By providing open-source accessibility and cost-efficiency, this work democratizes open-ended discovery across diverse computational problems.",https://www.semanticscholar.org/paper/58bccfcd425a9d45ce96c3b3e21c33e290b1ee2d,7,10.48550/arXiv.2509.19349,arXiv.org
solvingolympiadgeome-2024,Solving olympiad geometry without human demonstrations,Trieu H. Trinh; Yuhuai Wu; Quoc V. Le; He He; Thang Luong,2024,"Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning1–4, owing to their reputed difficulty among the world’s best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges1,5, resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004. A new neuro-symbolic theorem prover for Euclidean plane geometry trained from scratch on millions of synthesized theorems and proofs outperforms the previous best method and reaches the performance of an olympiad gold medallist.",https://www.semanticscholar.org/paper/9b093787f9be3d480cd11f8ec6ca5b0e44050d6d,558,10.1038/s41586-023-06747-5,Nature
towardssolvingmorech-2025,Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving,Zhenwen Liang; Linfeng Song; Yang Li; Tao Yang; Feng Zhang; Haitao Mi; Dong Yu,2025,"Automated Theorem Proving (ATP) in formal languages is a foundational challenge for AI. While Large Language Models (LLMs) have driven remarkable progress, a significant gap remains between their powerful informal reasoning capabilities and their weak formal proving performance. Recent studies show that the informal accuracy exceeds 80% while formal success remains below 8% on benchmarks like PutnamBench. We argue this gap persists because current state-of-the-art provers, by tightly coupling reasoning and proving, are trained with paradigms that inadvertently punish deep reasoning in favor of shallow, tactic-based strategies. To bridge this fundamental gap, we propose a novel framework that decouples high-level reasoning from low-level proof generation. Our approach utilizes two distinct, specialized models: a powerful, general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an efficient Prover to rigorously verify them. This modular design liberates the model's full reasoning potential and bypasses the pitfalls of end-to-end training. We evaluate our method on a challenging set of post-2000 IMO problems, a problem set on which no prior open-source prover has reported success. Our decoupled framework successfully solves 5 of these problems, demonstrating a significant step towards automated reasoning on exceptionally difficult mathematical challenges. To foster future research, we release our full dataset of generated and verified lemmas for a wide range of IMO problems, available at https://tencent-imo.github.io/ .",https://www.semanticscholar.org/paper/b308f9f7e60e04c33319f7459993bb33d5aff763,4,10.48550/arXiv.2507.06804,arXiv.org
universaldifferentia-2023,Universal differential equations for glacier ice flow modelling,Jordi Bolibar; Facundo Sapienza; F. Maussion; Redouane Lguensat; B. Wouters; Fernando Pérez,2023,"Abstract. Geoscientific models are facing increasing challenges to exploit growing datasets coming from remote sensing. Universal differential equations (UDEs), aided by differentiable programming, provide a new scientific modelling paradigm enabling both complex functional inversions to potentially discover new physical laws and data assimilation from heterogeneous and sparse observations. We demonstrate an application of UDEs as a proof of concept to learn the creep component of ice flow, i.e. a nonlinear diffusivity differential equation, of a glacier evolution model. By combining a mechanistic model based on a two-dimensional shallow-ice approximation partial differential equation with an embedded neural network, i.e. a UDE, we can learn parts of an equation as nonlinear functions that then can be translated into mathematical expressions. We implemented this modelling framework as ODINN.jl, a package in the Julia programming language, providing high performance, source-to-source automatic differentiation (AD) and seamless integration with tools and global datasets from the Open Global Glacier Model in Python. We demonstrate this concept for 17 different glaciers around the world, for which we successfully recover a prescribed artificial law describing ice creep variability by solving ∼ 500 000 ordinary differential equations in parallel. Furthermore, we investigate which are the best tools in the scientific machine learning ecosystem in Julia to differentiate and optimize large nonlinear diffusivity UDEs. This study represents a proof of concept for a new modelling framework aiming at discovering empirical laws for large-scale glacier processes, such as the variability in ice creep and basal sliding for ice flow, and new hybrid surface mass balance models.",https://www.semanticscholar.org/paper/472ecb54afa8ed28a53c29b2f5dae533454f5927,35,10.5194/gmd-16-6671-2023,Geoscientific Model Development
universeofthoughtsen-2025,Universe of Thoughts: Enabling Creative Reasoning with Large Language Models,Yuto Suzuki; F. Banaei-Kashani,2025,"Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \textit{combinational}, \textit{exploratory}, and \textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \textit{Universe of Thoughts} (or \textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.",https://www.semanticscholar.org/paper/6f047cd91c2456f1e53bd16ba4af6a852ed0dc3b,,,
usingreasoningmodels-2025,Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems,Christopher D. Rosin,2025,"Large Language Models (LLMs) with reasoning are trained to iteratively generate and refine their answers before finalizing them, which can help with applications to mathematics and code generation. We apply code generation with reasoning LLMs to a specific task in the mathematical field of combinatorial design. This field studies diverse types of combinatorial designs, many of which have lists of open instances for which existence has not yet been determined. The Constructive Protocol CPro1 uses LLMs to generate search heuristics that have the potential to construct solutions to small open instances. Starting with a textual definition and a validity verifier for a particular type of design, CPro1 guides LLMs to select and implement strategies, while providing automated hyperparameter tuning and execution feedback. CPro1 with reasoning LLMs successfully solves long-standing open instances for 7 of 16 combinatorial design problems selected from the 2006 Handbook of Combinatorial Designs, including new solved instances for 3 of these (Bhaskar Rao Designs, Symmetric Weighing Matrices, Balanced Ternary Designs) that were unsolved by CPro1 with non-reasoning LLMs. It also solves open instances for several problems from recent (2025) literature, generating new Covering Sequences, Johnson Clique Covers, Deletion Codes, and a Uniform Nested Steiner Quadruple System.",https://www.semanticscholar.org/paper/043d886c710206b2154ac9b1990bd93e44ee83ef,2,10.48550/arXiv.2505.23881,arXiv.org